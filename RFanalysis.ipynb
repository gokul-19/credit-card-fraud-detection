{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##INSTALL"
      ],
      "metadata": {
        "id": "eNtNeGHNRs0x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##IMPORTS"
      ],
      "metadata": {
        "id": "fXEVG9fmGlY1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier"
      ],
      "metadata": {
        "id": "2Mr0_-HSttpS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##LOAD DATA"
      ],
      "metadata": {
        "id": "8sQIebWjG2Ro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/AIML Dataset.csv\")"
      ],
      "metadata": {
        "id": "9DRRhw3NSmyo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PREPROCESSING"
      ],
      "metadata": {
        "id": "0pukmxszuvSR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat_cols = [\"type\", \"nameOrig\", \"nameDest\"]\n",
        "encoders = {}\n",
        "\n",
        "for col in cat_cols:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "    encoders[col] = le\n",
        "\n",
        "# Define features and target\n",
        "X = df.drop([\"isFraud\", \"isFlaggedFraud\"], axis=1)\n",
        "y = df[\"isFraud\"]\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.25, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Scale numeric values\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Save the scaler\n",
        "with open(\"scaler.pkl\", \"wb\") as f:\n",
        "    pickle.dump(scaler, f)\n",
        "\n",
        "print(\"Scaler saved: scaler.pkl\")"
      ],
      "metadata": {
        "id": "iZ37ZHH7uKTF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99f599e3-9788-48b2-f6d4-9a333c30a15f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scaler saved: scaler.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##MODEL TRAINING"
      ],
      "metadata": {
        "id": "V39yhtc9oOR-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    \"logistic_regression\": LogisticRegression(max_iter=500),\n",
        "    \"random_forest\": RandomForestClassifier(n_estimators=300, max_depth=10),\n",
        "    \"gradient_boosting\": GradientBoostingClassifier(),\n",
        "    \"xgboost\": XGBClassifier(\n",
        "        n_estimators=300,\n",
        "        learning_rate=0.1,\n",
        "        max_depth=6,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        eval_metric=\"logloss\"\n",
        "    )\n",
        "}\n",
        "\n",
        "# Train & save each model\n",
        "for name, model in models.items():\n",
        "    print(f\"Training {name}...\")\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "\n",
        "    # Save model\n",
        "    filename = f\"{name}.pkl\"\n",
        "    with open(filename, \"wb\") as f:\n",
        "        pickle.dump(model, f)\n",
        "\n",
        "    print(f\"Saved: {filename}\")"
      ],
      "metadata": {
        "id": "s15BCAM6oROf",
        "outputId": "2e162524-5353-40ab-ada2-890e1cef5761",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training logistic_regression...\n",
            "Saved: logistic_regression.pkl\n",
            "Training random_forest...\n",
            "Saved: random_forest.pkl\n",
            "Training gradient_boosting...\n",
            "Saved: gradient_boosting.pkl\n",
            "Training xgboost...\n",
            "Saved: xgboost.pkl\n"
          ]
        }
      ]
    }
  ]
}